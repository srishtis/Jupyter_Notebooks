{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:block\">\n",
    "    <div style=\"width: 20%; display: inline-block; text-align: left;\">\n",
    "        <img src=\"http://upload.wikimedia.org/wikipedia/en/0/0c/Mu_Sigma_Logo.jpg\" style=\"height:75px; margin-left:0px\" />\n",
    "    </div>\n",
    "    <div style=\"width: 59%; display: inline-block\">\n",
    "        <h1  style=\"text-align: center\">ML using Python: Session 1</h1>\n",
    "        <div style=\"width: 100%; text-align: center; display: inline-block;\"><i>Author:</i> <strong>Srishti Saha</strong> </div>\n",
    "    </div>\n",
    "    <div style=\"width: 20%; text-align: right; display: inline-block;\">\n",
    "        <div style=\"width: 100%; text-align: left; display: inline-block;\">\n",
    "            <i>Created: </i>\n",
    "            <time datetime=\"2014-03-10\" pubdate>9th February 2019</time>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics Covered:\n",
    "\n",
    "\n",
    "## 1. Sampling\n",
    "find link here: [Sampling](#Sampling)\n",
    "## 2. Basics of Hypothesis Testing\n",
    "find link here: [Basics of Hypothesis Testing](#Basics-of-Hypothesis-Testing)\n",
    "## 3. Hypothesis Testing\n",
    "find link here: [Hypothesis Testing](#Hypothesis-Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sampling method is a procedure for selecting sample members from a population. This is often done to reduce the size of data for an analysis depending on the ask.\n",
    "\n",
    "References:\n",
    "1. Different types of sampling: https://www.healthknowledge.org.uk/public-health-textbook/research-methods/1a-epidemiology/methods-of-sampling-population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  \n",
      "0     15.3  396.90   4.98  \n",
      "1     17.8  396.90   9.14  \n",
      "2     17.8  392.83   4.03  \n",
      "3     18.7  394.63   2.94  \n",
      "4     18.7  396.90   5.33  \n"
     ]
    }
   ],
   "source": [
    "# load a sample dataset\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "#using the Boston pricing dataset\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data)\n",
    "df.columns = boston.feature_names\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case each individual is chosen entirely by chance and each member of the population has an equal chance, or probability, of being selected. One way of obtaining a random sample is to give each individual in a population a number, and then use a table of random numbers to decide which individuals to include.1 For example, if you have a sampling frame of 1000 individuals, labelled 0 to 999, use groups of three digits from the random number table to pick your sample. So, if the first three numbers from the random number table were 094, select the individual labelled “94”, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 13)\n",
      "(380, 13)\n"
     ]
    }
   ],
   "source": [
    "# random sampling with number of rows\n",
    "df.sample(n=3)\n",
    "\n",
    "# random sampling with fraction\n",
    "df.sample(frac=0.25) #here 25% of rows are selected\n",
    "\n",
    "# for non overlapping two sets-- use random state\n",
    "subset1 = df.sample(frac=0.25, random_state=99)\n",
    "# this code tries to find that train = 75% and test = 25%\n",
    "subset2 = df.loc[~df.index.isin(subset1.index), :]\n",
    "print(subset1.shape)\n",
    "print(subset2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method, the population is first divided into subgroups (or strata) who all share a similar characteristic. It is used when we might reasonably expect the measurement of interest to vary between the different subgroups, and we want to ensure representation from all the subgroups. For example, in a study of stroke outcomes, we may stratify the population by sex, to ensure equal representation of men and women. The study sample is then obtained by taking equal sample sizes from each stratum. In stratified sampling, it may also be appropriate to choose non-equal sample sizes from each stratum. For example, in a study of the health outcomes of nursing staff in a county, if there are three hospitals each with different numbers of nursing staff (hospital A has 500 nurses, hospital B has 1000 and hospital C has 2000), then it would be appropriate to choose the sample numbers from each hospital proportionally (e.g. 10 from hospital A, 20 from hospital B and 40 from hospital C). This ensures a more realistic and accurate estimation of the health outcomes of nurses across the county, whereas simple random sampling would over-represent nurses from hospitals A and B. The fact that the sample was stratified should be taken into account at the analysis stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAD\n",
      "1.0      20\n",
      "2.0      24\n",
      "3.0      38\n",
      "4.0     110\n",
      "5.0     115\n",
      "6.0      26\n",
      "7.0      17\n",
      "8.0      24\n",
      "24.0    132\n",
      "dtype: int64\n",
      "(379, 13)\n",
      "(127, 13)\n",
      "RAD\n",
      "1.0     15\n",
      "2.0     18\n",
      "3.0     28\n",
      "4.0     82\n",
      "5.0     86\n",
      "6.0     20\n",
      "7.0     13\n",
      "8.0     18\n",
      "24.0    99\n",
      "dtype: int64\n",
      "RAD\n",
      "1.0      5\n",
      "2.0      6\n",
      "3.0     10\n",
      "4.0     28\n",
      "5.0     29\n",
      "6.0      6\n",
      "7.0      4\n",
      "8.0      6\n",
      "24.0    33\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# choosing the column RAD for stratified sampling due to finite number of values\n",
    "print(df.groupby(['RAD']).size()) #gets the distributions\n",
    "\n",
    "df_subset1, df_subset2 = model_selection.train_test_split(df, test_size=0.25, stratify=df['RAD'])\n",
    "print(df_subset1.shape)\n",
    "print(df_subset2.shape)\n",
    "print(df_subset1.groupby(['RAD']).size())\n",
    "print(df_subset2.groupby(['RAD']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two more techniques for probability based sampling techniques:\n",
    "1. **Systematic sampling**: Individuals are selected at regular intervals from the sampling frame. The intervals are chosen to ensure an adequate sample size. If you need a sample size n from a population of size x, you should select every x/nth individual for the sample.  For example, if you wanted a sample size of 100 from a population of 1000, select every 1000/100 = 10th member of the sampling frame.\n",
    "\n",
    "*Kindly note: Systematic sampling is often more convenient than simple random sampling, and it is easy to administer. However, it may also lead to bias, for example if there are underlying patterns in the order of the individuals in the sampling frame, such that the sampling technique coincides with the periodicity of the underlying pattern.*\n",
    "\n",
    "2. **Clustered Sampling**: In a clustered sample, subgroups of the population are used as the sampling unit, rather than individuals. The population is divided into subgroups, known as clusters, which are randomly selected to be included in the study. Clusters are usually already defined, for example individual GP practices or towns could be identified as clusters. In single-stage cluster sampling, all members of the chosen clusters are then included in the study. In two-stage cluster sampling, a selection of individuals from each cluster is then randomly selected for inclusion. In two-stage cluster sampling, a selection of individuals from each cluster is then randomly selected for inclusion.\n",
    "\n",
    "*Kindly note:  Typically one would prefer cluster sampling if it is hard or expensive to visit each group/stratum as is required in stratified random sampling.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In hypothesis testing, we have to define a null hypothesis (H0) and a corresponding alternative hypothesis (Ha).\n",
    "\n",
    "1. How do we choose between H0 and Ha? The standard procedure is to assume H0 is true - just as we presume innocent until proven guilty. Using probability theory, we try to determine whether there is sufficient evidence to declare H0 false.\n",
    "2. We reject H0 only when the chance is small that H0 is true. Since our decisions\n",
    "are based on probability rather than certainty, we can make errors.\n",
    "3. Type I error - We reject the null hypothesis when the null is true. The probability of Type I error = α. This means, *α = Probability of Type I error = P(rejecting H0 | H0 is true)*\n",
    "\n",
    "*Please Note: Typical values chosen for α (alpha) are .05 or .01. So, for example, if α = .05, there is a 5% chance that, when the null hypothesis is true, we will erroneously reject it.*\n",
    "4. Type II error - we accept the null hypothesis when it is not true. Probability of Type II error = ß (beta). Also means, *ß = Probability of Type II error = P(accepting H0 | H0 is false)*\n",
    "\n",
    "![Type 1 and Type 2 errors](https://wiki.mu-sigma.com/muwiki/images/8/8a/Type12_error.png)\n",
    "\n",
    "**example of type I and type II error:**\n",
    "\n",
    "H0: µ = 100\n",
    "Ha: µ <> 100 \n",
    "\n",
    "Suppose µ (mean) really does equal 100. But, suppose the researcher accepts HA instead. A type I error has occurred.\n",
    "Or, suppose µ = 105 : but the researcher accepts H0. A type II error has occurred.\n",
    "\n",
    "**Some important points**\n",
    "\n",
    "1. α and ß are not independent of each other - as one increases, the other decreases. However, increases in N (sample size) cause both to decrease, since sampling error is reduced.\n",
    "\n",
    "2. Normally, we primarily focus on Type I error. But, you should be aware that Type II error is also important. A small sample size, for example, might lead to frequent Type II errors, i.e. it could be that your (alternative) hypotheses are right, but because your sample is so small, you fail to reject the null even though you should. \n",
    "\n",
    "Reference:\n",
    "1. About Hypothesis testing and errors: https://www3.nd.edu/~rwilliam/stats1/x24.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-tailed and Two-tailed tests\n",
    "\n",
    "The _significance level_, also denoted as alpha or α, is the probability of rejecting the null hypothesis when it is true. For example, a significance level of 0.05 indicates a 5% risk of concluding that a difference exists when there is no actual difference.\n",
    "\n",
    "**What is a two-tailed test?**\n",
    "![Two Tailed Tests](https://wiki.mu-sigma.com/muwiki/images/1/11/Twotailed.png)\n",
    "First let’s start with the meaning of a two-tailed test.  If you are using a significance level of 0.05, a two-tailed test allots half of your alpha to testing the statistical significance in one direction and half of your alpha to testing statistical significance in the other direction.  This means that .025 is in each tail of the distribution of your test statistic. When using a two-tailed test, regardless of the direction of the relationship you hypothesize, you are testing for the possibility of the relationship in both directions.  For example, we may wish to compare the mean of a sample to a given value x using a t-test.  Our null hypothesis is that the mean is equal to x. A two-tailed test will test both if the mean is significantly greater than x and if the mean significantly less than x. The mean is considered significantly different from x if the test statistic is in the top 2.5% or bottom 2.5% of its probability distribution, resulting in a p-value less than 0.05.  \n",
    "\n",
    "**What is a one-tailed test?**\n",
    "![One Tailed Tests](https://wiki.mu-sigma.com/muwiki/images/b/bb/Onetailed.png)\n",
    "If you are using a significance level of .05, a one-tailed test allots all of your alpha to testing the statistical significance in the one direction of interest.  This means that .05 is in one tail of the distribution of your test statistic. When using a one-tailed test, you are testing for the possibility of the relationship in one direction and completely disregarding the possibility of a relationship in the other direction.  Let’s return to our example comparing the mean of a sample to a given value x using a t-test.  Our null hypothesis is that the mean is equal to x. A one-tailed test will test either if the mean is significantly greater than x or if the mean is significantly less than x, but not both. Then, depending on the chosen tail, the mean is significantly greater than or less than x if the test statistic is in the top 5% of its probability distribution or bottom 5% of its probability distribution, resulting in a p-value less than 0.05.  The one-tailed test provides more power to detect an effect in one direction by not testing the effect in the other direction. \n",
    "\n",
    "**Should you choose one tailed test?**\n",
    "Although one tailed tests have more power in detecting the effect, one should consider the consequences of missing an effect in the other direction. \n",
    "If you consider the consequences of missing an effect in the untested direction and conclude that they are negligible and in no way irresponsible or unethical, then you can proceed with a one-tailed test. For example, imagine again that you have developed a new drug. It is cheaper than the existing drug and, you believe, no less effective.  In testing this drug, you are only interested in testing if it less effective than the existing drug.  You do not care if it is significantly more effective.  You only wish to show that it is not less effective. In this scenario, a one-tailed test would be appropriate. \n",
    "\n",
    "\n",
    "For more content refer to this: https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/\n",
    "\n",
    "References:\n",
    "1. Hypothesis Testing: https://www.analyticsvidhya.com/blog/2015/09/hypothesis-testing-explained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z value is a measure of standard deviation i.e. how many standard deviation away from mean is the observed value. For example, the value of z value = +1.8 can be interpreted as the observed value is +1.8 standard deviations away from the mean.\n",
    "In this test, we check where the mean of an entire sample of observations falls with regards to the mean of the sampling distribution.\n",
    "\n",
    "**Basic Assumption: Z-test is a statistical test where normal distribution is applied and is basically used for dealing with problems relating to large samples when n ≥ 30.**\n",
    "\n",
    "A z-score can be calculated from the following formula:\n",
    "\n",
    "_z = (X - μ) / σ_\n",
    "where z is the z-score, X is the value of the element, μ is the population mean, and σ is the standard deviation.\n",
    "\n",
    "**How to read z-scores?**\n",
    "\n",
    "1. A z-score less than 0 represents an element less than the mean.\n",
    "\n",
    "2. A z-score equal to 0 represents an element equal to the mean.\n",
    "\n",
    "3. A z-score equal to 1 represents an element that is 1 standard deviation greater than the mean; a z-score equal to 2, 2 standard deviations greater than the mean; etc.\n",
    "\n",
    "_1.In a two-tailed z-test, if z-score is greater than 1.96 or lower than -1.96 (i.e 0.025 of the total area under the curve), we reject the null hypothesis._\n",
    "\n",
    "_2.In a one-tailed upper test, if z-score is greater than 1.645 (i.e 0.05 of the total area under the curve), we reject the null hypothesis._\n",
    "\n",
    "_3.In a one-tailed lower test, if z-score is lesser than -1.645 (i.e 0.05 of the total area under the curve), we reject the null hypothesis._ \n",
    "\n",
    "Reading Material:\n",
    "1. When to use Z-test: https://explorable.com/z-test\n",
    "2. Steps in Z-test: http://jukebox.esc13.net/untdeveloper/RM/Stats_Module_4/mobile_pages/Stats_Module_48.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "#import scipy.special as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-score is: 1.9999999999999996\n",
      "p-value is: 0.04550026389635842\n"
     ]
    }
   ],
   "source": [
    "n = 100  # total number of samples\n",
    "h = 60  # number of heads\n",
    "q = .5  # null-hypothesis\n",
    "\n",
    "xbar = float(h) / n #xbar is the estimated average of the distribution\n",
    "z = (xbar - q) * np.sqrt(n / (q * (1 - q))) #z-score\n",
    "\n",
    "# you cam also compute the p-value from here\n",
    "pval = 2 * (1 - st.norm.cdf(z))\n",
    "\n",
    "print('z-score is:', z)\n",
    "print('p-value is:',pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the p-value is less than 0.05, so we reject the null hypothesis. This is equivalent to a z-score greater than 1.96 for two-tailed tests (or less than -1.96) or 1.645 for one-tailed tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pre-built package\n",
    "\n",
    "\n",
    "# Demonstrating significant differences between a\n",
    "# vector of measurements and a single value\n",
    "# Using the statsmodels package for doing test\n",
    "# Using numpy to generate some fake data\n",
    "\n",
    "from statsmodels.stats import weightstats as stests\n",
    "\n",
    "data=np.random.normal(loc=3.4,scale=0.1,size=50)\n",
    "mean_val=3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3995309243434235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.46688617, 3.34824285, 3.4701035 , 3.34296253, 3.33732259,\n",
       "       3.61711696, 3.26877826, 3.40741498, 3.25690456, 3.27580067,\n",
       "       3.27651429, 3.31794618, 3.52201481, 3.33544749, 3.67260567,\n",
       "       3.32255301, 3.62123748, 3.34813981, 3.46011782, 3.43284188,\n",
       "       3.31451055, 3.1463677 , 3.50018329, 3.3322575 , 3.60210048,\n",
       "       3.33272494, 3.57944554, 3.48798935, 3.32731935, 3.32970678,\n",
       "       3.31734386, 3.20751351, 3.54224971, 3.39977574, 3.4634891 ,\n",
       "       3.39989585, 3.39758015, 3.42157339, 3.40598136, 3.40711931,\n",
       "       3.37500965, 3.23087303, 3.38461542, 3.33210847, 3.41069967,\n",
       "       3.6178106 , 3.44418453, 3.42810676, 3.36374396, 3.37331513])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value is: 4.2412250540942237e-10\n",
      "Z-test statistic is -6.24488114209153\n"
     ]
    }
   ],
   "source": [
    "# Assuming data are normally distributed, we can do z-test\n",
    "test_statistic, p_value =stests.ztest(data,value=mean_val)\n",
    "print(\"p-value is: \"+str(p_value))\n",
    "print(\"Z-test statistic is \" + str(test_statistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the default value of the argument 'alternative' has been taken into account. i.e. this is a two-tailed hypothesis. In this case, our alternative hypothesis was of the form:\n",
    "**mean != man_val**\n",
    "\n",
    "We can also explore the one-tailed hypotheses.\n",
    "Let us set the the null hypothesis as: \n",
    "**mean < mean_value**.\n",
    "Then, alternative hypothesis is mean > mean_value.\n",
    "We choose the value of the argument 'alternative' as _'larger'_\n",
    "\n",
    "In the scenario, you create a null hypothesis like mean > mean_value, choose _'smaller'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-test statistic is -6.24488114209153\n",
      "p-value is 0.9999999997879387\n"
     ]
    }
   ],
   "source": [
    "test_statistic2, p_value2 = stests.ztest(data,value=mean_val, \n",
    "                                         alternative='larger')\n",
    "\n",
    "print(\"Z-test statistic is \" + str(test_statistic2))\n",
    "print(\"p-value is \" + str(p_value2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_HypothesisTest-Means-Proportions/BS704_HypothesisTest-Means-Proportions3.html\n",
    "2. https://www.statsmodels.org/dev/generated/statsmodels.stats.weightstats.ztest.html\n",
    "3. https://www.analyticsvidhya.com/blog/2015/09/hypothesis-testing-explained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t test (also called Student’s T Test) compares two averages (means) and tells you if they are different from each other. The t test also tells you how significant the differences are; In other words it lets you know if those differences could have happened by chance.\n",
    "\n",
    "**Basic Assumptions:**\n",
    "**1. Observations in each sample are independent and identically distributed (iid).**\n",
    "**2. Observations in each sample are normally distributed.**\n",
    "**3. Observations in each sample have the same variance.**\n",
    "\n",
    "The t score is a ratio between the difference between two groups and the difference within the groups. \n",
    "\n",
    "**How to read a t-score?**\n",
    "\n",
    "The larger the t score, the more difference there is between groups. The smaller the t score, the more similarity there is between groups. A t-score of 3 means that the groups are three times as different from each other as they are within each other. When you run a t test, the bigger the t-value, the more likely it is that the results are repeatable.\n",
    "\n",
    "1. A large t-score tells you that the groups are different.\n",
    "2. A small t-score tells you that the groups are similar.\n",
    "\n",
    "Just like the z-score, every value of t-score corresponds to a p-value (probability that the results from your sample data occurred by chance). You reject the null hypothesis when p < 0.05\n",
    "\n",
    "**Different types of T-test**\n",
    "There are three different types of T-tests:\n",
    "1. Correlated (Paired/ Dependent) T-test: The correlated T test is performed when the samples typically consist of matched pairs of similar units, or when there are cases of repeated measures.\n",
    "2. Independent equal-variance (pooled) T-test: The equal variance T test is used when the number of samples in each groups is the same, or the variance of the two data sets is similar.\n",
    "3. Independent unequal-variance T-test: The unequal variance T test is used when the number of samples in each group is different and the variance of the two data sets is also different. This test is also called the **Welch's t-test.** \n",
    "\n",
    "![Selection of T-Test](https://wiki.mu-sigma.com/muwiki/images/c/c7/Select_ttest.png)\n",
    "\n",
    "Reading material:\n",
    "1. https://www.investopedia.com/terms/t/t-test.asp\n",
    "2. https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_ind.html\n",
    "3. http://blog.minitab.com/blog/adventures-in-statistics-2/understanding-t-tests-t-values-and-t-distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 15.56673473136405\n",
      "two tailed p-value = 6.583946221216434e-36\n",
      "one tailed p-value = 3.291973110608217e-36\n"
     ]
    }
   ],
   "source": [
    "#independent equal variance tests\n",
    "\n",
    "# generate two independent samples\n",
    "# define sample size:N\n",
    "N=100\n",
    "#Gaussian distributed data with mean = 2 and var = 1\n",
    "data1 = np.random.randn(N) + 2\n",
    "#Gaussian distributed data with with mean = 0 and var = 1\n",
    "data2 = np.random.randn(N)\n",
    "# compare samples\n",
    "tstat, p = st.ttest_ind(data1, data2)\n",
    "\n",
    "print(\"t = \" + str(tstat))\n",
    "print(\"two tailed p-value = \" + str(2*p))\n",
    "print(\"one tailed p-value = \" + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note: The two-tail P value is twice the one-tail P value (assuming you correctly predicted the direction of the difference)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for **correlated T-test**: try the *ttest_rel* function from the same library\n",
    "\n",
    "\n",
    "for **independent unequal variance test**: use the equal_var : bool, optional\n",
    "If True (default), perform a standard independent 2 sample test that assumes equal population variances. If False, perform Welch’s t-test, which does not assume equal population variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An F-test is used to test if the variances of two populations are equal. Just like other hypothesis tests, this test can be a two-tailed test or a one-tailed test. The two-tailed version tests against the alternative that the variances are not equal. The one-tailed version only tests in one direction, that is the variance from the first population is either greater than or less than (but not both) the second population variance. The choice is determined by the problem. For example, if we are testing a new process, we may only be interested in knowing if the new process is less variable than the old process.\n",
    "\n",
    "In summary, the F-test can be used to answer the following questions:\n",
    "Do two samples come from populations with equal variancess?\n",
    "Does a new process, treatment, or test reduce the variability of the current process?\n",
    "\n",
    "**Basic Assumptions:**\n",
    "Your population must be **approximately normally distributed (i.e. fit the shape of a bell curve)** in order to use the test. Plus, the samples must be **independent events**. In addition, there are a few important points:\n",
    "\n",
    "1. The larger variance should always go in the numerator (the top number) to force the test into a right-tailed test. Right-tailed tests are easier to calculate.\n",
    "2. For two-tailed tests, divide alpha by 2 before finding the right critical value.\n",
    "3. If you are given standard deviations, they must be squared to get the variances.\n",
    "\n",
    "The F hypothesis test is defined as:\n",
    "\n",
    "H0 (null hypothesis):\t(σ1)^2=(σ2)^2\n",
    "\n",
    "Ha (alternative hypothesis):\t\n",
    "(σ1)^2<(σ2)^2\t   \tfor a lower one-tailed test;\n",
    "\n",
    "(σ1)^2>(σ2)^2\t   \tfor an upper one-tailed test;\n",
    "\n",
    "(σ1)^2≠(σ2)^2\t   \tfor a two-tailed test;\n",
    "\n",
    "Test Statistic:\tF = (s1)^2/(s2)^2\n",
    "\n",
    "where (s1)^2 and (s2)^2 and are the sample variances. The more this ratio deviates from 1, the stronger the evidence for unequal population variances.\n",
    "\n",
    "**How to consume the reults of the F-test?**\n",
    "You need to compare the computed F-value with the critical F-value obtained from the F-table on the basis of the degrees of freedom. If your calculated value is higher than the table value, you can reject the null hypothesis.\n",
    "\n",
    "You can also use the associated p-value to accept or reject the hypothesis. If p-value< alpha (generally 0.05), reject the null-hypothesis.\n",
    "\n",
    "Additional reading material:\n",
    "1. https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/hypothesis-testing/f-test/ and https://www.statisticshowto.datasciencecentral.com/tables/f-table/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyAstronomy import pyasl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 47.70582597  -1.32203058  30.66849347 -17.20159544  -2.89902441\n",
      "  36.10959867 -67.16032066  -5.98387133  11.31341947  37.11063587\n",
      "  12.46320061  56.96382437  46.89575867 -26.16749361  22.13872419\n",
      "  26.73464203  18.03711776  13.40600488  24.55749762  47.23028627\n",
      " -17.18334608   1.04089621 -18.00037599  23.44277722  46.7384864\n",
      "  -6.58805741 -27.41225595 -15.09141931 -40.20518903  25.56353673\n",
      "  32.270431    12.7877844   39.72983135 -47.52377031  17.02103989\n",
      "   7.44731445  -7.64639729   7.4872479    0.80478955  22.25139817\n",
      " -47.19218759  14.90560505  -8.1719195  -20.44936856 -30.41926798\n",
      " -12.84060523  23.80672931  19.49441783  -9.47703128  -0.53069519]\n",
      "[ -9.22143432   1.27456373 -18.13991654  -4.94164353   5.12786045\n",
      "   8.77920302  -1.81972474   1.16754898  -4.65653113   3.41834204\n",
      "   7.75260619   3.70345559 -14.29654719  -8.17986913  11.09569891\n",
      "   1.50708905  11.87024889  -1.50380106  -1.92848752 -11.27890823]\n",
      "dof1: 49\n",
      "dof2: 19\n",
      "Test Stats = {'F statistic': 5.066666666666666, 'p-value': 0.000251724169401113, 'Gaussian sigma level': 3.660499373637431}\n"
     ]
    }
   ],
   "source": [
    "# generate two independent samples\n",
    "# define sample size:N\n",
    "N1=50\n",
    "N2=20\n",
    "ch1=900\n",
    "ch2=100\n",
    "#Gaussian distributed data with mean = 2 and var = 900\n",
    "data1 = np.sqrt(ch1) * np.random.randn(N1) + 2\n",
    "#Gaussian distributed data with with mean = 0 and var = 100\n",
    "data2 = np.sqrt(ch2) * np.random.randn(N2)\n",
    "\n",
    "print(data1)\n",
    "print(data2)\n",
    "\n",
    "dof1=len(data1)-1\n",
    "dof2=len(data2)-1\n",
    "\n",
    "print('dof1:', dof1)\n",
    "print('dof2:', dof2)\n",
    "\n",
    "# simple Fisher's classical test\n",
    "# compare samples\n",
    "fval = pyasl.ftest(ch1,ch2,dof1, dof2)\n",
    "print(\"Test Stats = \" + str(fval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "package documentation can be found here: https://www.hs.uni-hamburg.de/DE/Ins/Per/Czesla/PyA/PyA/pyaslDoc/aslDoc/statTest.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ANOVA test or Analysis of Variance is a way to find out if survey or experiment results are significant. More specifically, it states whether your sample value closely matches what value you would expect to find in an entire population\n",
    "\n",
    "There are multiple kinds of ANOVA tests:\n",
    "1. One-way ANOVA test - A one way ANOVA is used to compare two means from two independent (unrelated) groups using the F-distribution. The null hypothesis for the test is that the two means are equal. Therefore, a significant result means that the two means are unequal.\n",
    "2. Two Way ANOVA - A Two Way ANOVA is an extension of the One Way ANOVA. With a One Way, you have one independent variable affecting a dependent variable. With a Two Way ANOVA, there are two independents. Use a two way ANOVA when you have one measurement variable (i.e. a quantitative variable) and two nominal variables. In other words, if your experiment has a quantitative outcome and you have two categorical explanatory variables, a two way ANOVA is appropriate.\n",
    "3. Factorial ANOVA - A factorial ANOVA is an Analysis of Variance test with more than one independent variable, or “factor“. It can also refer to more than one Level of Independent Variable. \n",
    "\n",
    "**How do we interpret results?**\n",
    "ANOVA tests give you an F-value and a corresponding p-value. Like all other tests, you can reject the null hypothesis if p<alpha (0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fval = 7.121019471642447\n",
      "p-value = 0.0002812242314534544\n"
     ]
    }
   ],
   "source": [
    "# One Way ANOVA test\n",
    "\n",
    "#create data\n",
    "tillamook = [0.0571, 0.0813, 0.0831, 0.0976, 0.0817, 0.0859, 0.0735,0.0659, 0.0923, 0.0836]\n",
    "newport = [0.0873, 0.0662, 0.0672, 0.0819, 0.0749, 0.0649, 0.0835,0.0725]\n",
    "petersburg = [0.0974, 0.1352, 0.0817, 0.1016, 0.0968, 0.1064, 0.105]\n",
    "magadan = [0.1033, 0.0915, 0.0781, 0.0685, 0.0677, 0.0697, 0.0764,0.0689]\n",
    "tvarminne = [0.0703, 0.1026, 0.0956, 0.0973, 0.1039, 0.1045]\n",
    "\n",
    "#conduct the test\n",
    "fval, pval=st.f_oneway(tillamook, newport, petersburg, magadan, tvarminne)\n",
    "\n",
    "print(\"fval = \" + str(fval))\n",
    "print(\"p-value = \" + str(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall model F( 5, 54) =  41.557, p =  0.0000\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    len   R-squared:                       0.794\n",
      "Model:                            OLS   Adj. R-squared:                  0.775\n",
      "Method:                 Least Squares   F-statistic:                     41.56\n",
      "Date:                Mon, 11 Feb 2019   Prob (F-statistic):           2.50e-17\n",
      "Time:                        11:55:13   Log-Likelihood:                -159.35\n",
      "No. Observations:                  60   AIC:                             330.7\n",
      "Df Residuals:                      54   BIC:                             343.3\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Intercept                       13.2300      1.148     11.521      0.000      10.928      15.532\n",
      "C(supp)[T.VC]                   -5.2500      1.624     -3.233      0.002      -8.506      -1.994\n",
      "C(dose)[T.1.0]                   9.4700      1.624      5.831      0.000       6.214      12.726\n",
      "C(dose)[T.2.0]                  12.8300      1.624      7.900      0.000       9.574      16.086\n",
      "C(supp)[T.VC]:C(dose)[T.1.0]    -0.6800      2.297     -0.296      0.768      -5.285       3.925\n",
      "C(supp)[T.VC]:C(dose)[T.2.0]     5.3300      2.297      2.321      0.024       0.725       9.935\n",
      "==============================================================================\n",
      "Omnibus:                        0.336   Durbin-Watson:                   2.025\n",
      "Prob(Omnibus):                  0.846   Jarque-Bera (JB):                0.324\n",
      "Skew:                           0.164   Prob(JB):                        0.850\n",
      "Kurtosis:                       2.852   Cond. No.                         9.77\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                      sum_sq    df          F        PR(>F)\n",
      "C(supp)           205.350000   1.0  15.571979  2.311828e-04\n",
      "C(dose)          2426.434333   2.0  91.999965  4.046291e-18\n",
      "C(supp):C(dose)   108.319000   2.0   4.106991  2.186027e-02\n",
      "Residual          712.106000  54.0        NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "# Two Way ANOVA Test\n",
    "\n",
    "#data file\n",
    "datafile = \"ToothGrowth.csv\"\n",
    "df = pd.read_csv(datafile)\n",
    "\n",
    "# Fits the model with the interaction term\n",
    "# This will also automatically include the main effects for each factor\n",
    "formula = 'len ~ C(supp) + C(dose) + C(supp):C(dose)'\n",
    "model = ols(formula, df).fit()\n",
    "\n",
    "# Seeing if the overall model is significant\n",
    "print(f\"Overall model F({model.df_model: .0f},{model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .4f}\")\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Create the ANOVA table\n",
    "aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s break down this ANOVA table. The top 3 rows show the between groups effect of the 3 components (supp, dose and 'supp x dose') which is the overall experimental effect. \n",
    "\n",
    "Say, in the first row (supp), the sum of squares for the model (SSM; value 2015.35 in the table) is how much variance is explained by that component in our model. The current model explains a significant amount of variance, F( 5, 54) =  41.557, p < 0.05. The residual row is the unsystematic variation in the data (SSR; also called the unexplained variance; value 712.106 in the table). \n",
    "\n",
    "While theseresults give an indication of whether there is a statistically significant effect of some factor on the outcome, it’s as important to know the size of the effect the factor has on the outcome. Statistical significance does not always translate into a large effect in the world.\n",
    "\n",
    "For the same, we introduce 2 new metrics:\n",
    "1. eta-squared (η^2): Eta Squared is calculated the same way as R Squared, and has the most equivalent interpretation: out of the total variation in Y, the proportion that can be attributed to a specific X. Eta Squared, however, is used specifically in ANOVA models. Each categorical effect in the model has its own Eta Squared, so you get a specific, intuitive measure of the effect of that variable.\n",
    "\n",
    "*Please note: Eta Squared has two drawbacks. One is that as you add more variables to the model, the proportion explained by any one variable will automatically decrease. This makes it hard to compare the effect of a single variable in different studies. The second drawback for eta Squared is that it is a biased measure of population variance explained (although it is accurate for the sample). It always overestimates it. This bias gets very small as sample size increases, but for small samples an unbiased effect size measure is Omega Squared.*\n",
    "\n",
    "\n",
    "2. omega-squared (ω^2): Omega squared (ω2) is a measure of effect size, or the degree of association for a population. It is an estimate of how much variance in the response variables are accounted for by the explanatory variables. Omega squared is widely viewed as a lesser biased alternative to eta-squared, especially when sample sizes are small.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      sum_sq    df          F        PR(>F)    eta_sq  \\\n",
      "C(supp)           205.350000   1.0  15.571979  2.311828e-04  0.059484   \n",
      "C(dose)          2426.434333   2.0  91.999965  4.046291e-18  0.702864   \n",
      "C(supp):C(dose)   108.319000   2.0   4.106991  2.186027e-02  0.031377   \n",
      "Residual          712.106000  54.0        NaN           NaN       NaN   \n",
      "\n",
      "                 omega_sq  \n",
      "C(supp)          0.055452  \n",
      "C(dose)          0.692579  \n",
      "C(supp):C(dose)  0.023647  \n",
      "Residual              NaN  \n"
     ]
    }
   ],
   "source": [
    "#functions to add omega squared and eta squared\n",
    "def eta_squared(aov):\n",
    "    aov['eta_sq'] = 'NaN'\n",
    "    aov['eta_sq'] = aov[:-1]['sum_sq']/sum(aov['sum_sq'])\n",
    "    return aov\n",
    " \n",
    "def omega_squared(aov):\n",
    "    #use residual to calculate mean squared error\n",
    "    mse = aov['sum_sq'][-1]/aov['df'][-1]\n",
    "    aov['omega_sq'] = 'NaN'\n",
    "    aov['omega_sq'] = (aov[:-1]['sum_sq']-(aov[:-1]['df']*mse))/(sum(aov['sum_sq'])+mse)\n",
    "    return aov\n",
    "\n",
    "#applying the function to aov_table\n",
    "eta_squared(aov_table)\n",
    "omega_squared(aov_table)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ω2 is a better measure of effect size since it’s unbiased in it’s calculation. It takes into account the degrees of freedom, whereas η2 does not. Side note, η2 and R2 are the same thing in the ANOVA framework.\n",
    "\n",
    "Higher the value of ω2 (or η2), more significant is the variable.\n",
    "\n",
    "Additional Reading Material:\n",
    "1. Effect size metrics: https://www.uccs.edu/lbecker/glm_effectsize\n",
    "2. 2 way ANOVA steps: https://pythonfordatascience.org/anova-2-way-n-way/\n",
    "3. Package documentation: https://www.statsmodels.org/dev/generated/statsmodels.stats.anova.anova_lm.html and https://www.statsmodels.org/dev/examples/notebooks/generated/interactions_anova.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi squared test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-square test (or **Pearson’s Chi-Squared Test**) is a nonparametric test used for two specific purpose: \n",
    "\n",
    "(a) To test the hypothesis of no association between two or more groups, population or criteria (i.e. to check independence between two variables); \n",
    "\n",
    "(b) and to test how likely the observed distribution of data fits with the distribution that is expected (i.e., to test the goodness-of-fit). \n",
    "\n",
    "**Please note: It is used to analyze categorical data (e.g. male or female patients, smokers and non-smokers, etc.), it is not meant to analyze parametric or continuous data (e.g., height measured in centimeters or weight measured in kg, etc.).**\n",
    "\n",
    "An ideal Hypothesis for chi-squared tests:\n",
    "\n",
    "1.Null hypothesis: Assumes that there is no association between the two variables.\n",
    "\n",
    "2.Alternative hypothesis: Assumes that there is an association between the two variables.\n",
    "\n",
    "**In other words, the Chi-Squared test is a statistical hypothesis test that states the null hypothesis as:\n",
    "two categorical variables are independent in a given population.** \n",
    "\n",
    "\n",
    "**Some basic assumptions:**\n",
    "1. The data are randomly drawn from a population.\n",
    "2. The sample size is sufficiently large. The application of the Chi-square test to a smaller sample could lead to type II error (i.e. accepting the null hypothesis when it is actually false). There is no expected cut-off for the sample size; however, the minimum sample size varies from 20 to 50\n",
    "3. The variables under consideration must be mutually exclusive. It means that each variable must only be counted once in a particular category and should not be allowed to appear in other category. In other, words no item shall be counted twice.\n",
    "\n",
    "**How to interpret the results?**\n",
    "The variables are considered independent if the observed (the categorically coded data that you have collected) and expected frequencies (frequencies that you would expect to get in each cell of a table by chance alone ) are similar.\n",
    "\n",
    "1. If Test Statistic >= Critical Value (p-value <= alpha): significant result, reject null hypothesis (H0), dependent.\n",
    "2. If Test Statistic < Critical Value (p-value > alpha): not significant result, fail to reject null hypothesis (H0), independent\n",
    "\n",
    "Additional Reading Material:\n",
    "1. http://www.j-pcs.org/article.asp?issn=2395-5414;year=2015;volume=1;issue=1;spage=69;epage=71;aulast=Rana\n",
    "2. https://machinelearningmastery.com/chi-squared-test-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 20, 30], [6, 9, 17]]\n",
      "dof=2\n",
      "[[10.43478261 18.91304348 30.65217391]\n",
      " [ 5.56521739 10.08695652 16.34782609]]\n",
      "probability=0.950, critical=5.991, stat=0.272\n",
      "Independent (fail to reject H0)\n",
      "significance=0.050, p=0.873\n",
      "Independent (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# chi-squared test with similar proportions\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "# contingency table-- summarizes the count of records between two categorical variables\n",
    "table = [\t[10, 20, 30],\n",
    "\t\t\t[6,  9,  17]]\n",
    "print(table)\n",
    "#The function (chi2_contingency) takes an array as input representing the contingency table for the two categorical variables. \n",
    "#It returns the calculated statistic and p-value for interpretation as well as the calculated degrees of freedom and table of expected frequencies.\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('dof=%d' % dof)\n",
    "print(expected)\n",
    "# interpret test-statistic\n",
    "prob = 0.95 #(assuming  that the variable is independent)\n",
    "critical = chi2.ppf(prob, dof) #Percent point function \n",
    "print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "if abs(stat) >= critical:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')\n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package doc:\n",
    "1. https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.chi2_contingency.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
